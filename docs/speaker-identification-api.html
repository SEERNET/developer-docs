<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Speaker Identification Api · DeepAffects</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="This API tries to figure out &quot;Who Speaks When&quot; for already enrolled speakers."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Speaker Identification Api · DeepAffects"/><meta property="og:type" content="website"/><meta property="og:url" content="https://deepaffects.com/index.html"/><meta property="og:description" content="This API tries to figure out &quot;Who Speaks When&quot; for already enrolled speakers."/><meta property="og:image" content="https://deepaffects.com/img/docusaurus.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://deepaffects.com/img/docusaurus.png"/><link rel="shortcut icon" href="/img/favicon/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><link rel="stylesheet" href="/css/main.css"/></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/deepaffects-logo.png" alt="DeepAffects"/><h2 class="headerTitleWithLogo">DeepAffects</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/introduction.html" target="_self">Docs</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>Generic Audio Analysis</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Get Started</h3><ul><li class="navListItem"><a class="navItem" href="/docs/introduction.html">Introduction</a></li><li class="navListItem"><a class="navItem" href="/docs/quick-start.html">Quickstart Guide</a></li><li class="navListItem"><a class="navItem" href="/docs/authentication.html">Authentication</a></li><li class="navListItem"><a class="navItem" href="/docs/errors.html">Errors</a></li><li class="navListItem"><a class="navItem" href="/docs/concepts.html">Concepts</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Generic Audio Analysis</h3><ul><li class="navListItem"><a class="navItem" href="/docs/audio-denoising-api.html">Audio Denoising Api</a></li><li class="navListItem"><a class="navItem" href="/docs/speaker-diairization-api.html">Speaker Diarization Api</a></li><li class="navListItem"><a class="navItem" href="/docs/paralinguistic-feature-extraction-api.html">Paralinguistic Feature Extraction Api</a></li><li class="navListItem"><a class="navItem" href="/docs/emotion-recognition-api.html">Emotion Recognition Api</a></li><li class="navListItem"><a class="navItem" href="/docs/realtime-emotion-recognition-api.html">Realtime Emotion Recognition Api</a></li><li class="navListItem"><a class="navItem" href="/docs/speaker-enrollment-api.html">Speaker Enrollment Api</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/docs/speaker-identification-api.html">Speaker Identification Api</a></li><li class="navListItem"><a class="navItem" href="/docs/realtime-speaker-identification-api.html">Realtime Speaker Identification Api</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Custom Audio Analysis</h3><ul><li class="navListItem"><a class="navItem" href="/docs/depression-prediction-api.html">Depression Prediction Api</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Generic Text Analysis</h3><ul><li class="navListItem"><a class="navItem" href="/docs/text-emotion-recognition-api.html">Text Emotion Recognition Api</a></li></ul></div></div></section></div><script>
            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              const headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                if (event.target.tagName === 'A') {
                  document.body.classList.remove('tocActive');
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Speaker Identification Api</h1></header><article><div><span><p>This API tries to figure out &quot;Who Speaks When&quot; for already enrolled speakers.
Splits audio clip into segments corresponding to a unique speaker and returns start and end of the segment</p>
<h3><a class="anchor" aria-hidden="true" id="post-request"></a><a href="#post-request" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>POST Request</h3>
<h3><a class="anchor" aria-hidden="true" id="async"></a><a href="#async" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Async</h3>
<p><br />
<code>POST https://proxy.api.deepaffects.com/audio/generic/api/v1/async/diarization/identify</code> - Low latency, Good accuracy
<br />
<code>POST https://proxy.api.deepaffects.com/audio/generic/api/v2/async/diarization/identify</code> - More latency, Better accuracy
<br />
<code>POST https://proxy.api.deepaffects.com/audio/generic/api/v3/async/diarization/identify</code> -  High latency, Best accuracy
<br /></p>
<h3><a class="anchor" aria-hidden="true" id="sync"></a><a href="#sync" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sync</h3>
<p><br />
<code>POST https://proxy.api.deepaffects.com/audio/generic/api/v1/sync/diarization/identify</code> - Low latency, Good accuracy
<br />
<code>POST https://proxy.api.deepaffects.com/audio/generic/api/v2/sync/diarization/identify</code> -  High latency, Best accuracy</p>
<h3><a class="anchor" aria-hidden="true" id="sample-code"></a><a href="#sample-code" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Sample Code</h3>
<h3><a class="anchor" aria-hidden="true" id="shell"></a><a href="#shell" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Shell</h3>
<pre><code class="hljs css languages- shell">curl -X POST "https://proxy.api.deepaffects.com/audio/generic/api/v3/async/diarization/identify?apikey=&lt;ACCESS_TOKEN&gt;&amp;webhook=&lt;WEBHOOK_URL&gt;&amp;request_id=&lt;REQUEST_ID&gt;" -H 'content-type: application/json' -d @data.json

curl -X POST "https://proxy.api.deepaffects.com/audio/generic/api/v2/sync/diarization/identify?apikey=&lt;ACCESS_TOKEN&gt;" -H 'content-type: application/json' -d @data.json
<span class="hljs-meta">
#</span><span class="bash"> contents of data.json</span>
{"content": "bytesEncodedAudioString", "sampleRate": 8000, "encoding": "FLAC", "languageCode": "en-US", speakerIds: ["user1"]}
</code></pre>
<pre><code class="hljs css languages- shell"><span class="hljs-meta">#</span><span class="bash"> The above <span class="hljs-built_in">command</span> returns output ( Async ):</span>
{
  "request_id": "request_id_example",
  "api": "/audio/generic/api/v3/async/diarization/identify"
}
<span class="hljs-meta">#</span><span class="bash"> The above <span class="hljs-built_in">command</span> returns output ( Sync ):</span>
[
  {
  "speakerId": "user1",
  "start": 0,
  "end": 2
  }
]
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="body-parameters"></a><a href="#body-parameters" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Body Parameters</h3>
<table>
<thead>
<tr><th>Parameter</th><th>Type</th><th>Description</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>encoding</td><td>String</td><td>Encoding of audio file like MP3, WAV etc.</td></tr>
<tr><td>sampleRate</td><td>Number</td><td>Sample rate of the audio file.</td></tr>
<tr><td>languageCode</td><td>String</td><td>Language spoken in the audio file.</td><td>[default to 'en-US']</td></tr>
<tr><td>content</td><td>String</td><td>base64 encoding of the audio file.</td></tr>
<tr><td>speakerIds</td><td>List[String]</td><td>List of enrolled speakers to identify</td><td></td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="query-parameters"></a><a href="#query-parameters" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Query Parameters</h3>
<table>
<thead>
<tr><th>Parameter</th><th>Type</th><th>Description</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>api_key</td><td>String</td><td>The apikey</td><td>Required for authentication inside all requests</td></tr>
<tr><td>webhook</td><td>String</td><td>The webhook url at which the responses will be sent</td><td>Required for async requests</td></tr>
<tr><td>request_id</td><td>Number</td><td>An optional unique id to link async response with the original request</td><td>Optional</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="output-parameters-async"></a><a href="#output-parameters-async" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Output Parameters (Async)</h3>
<table>
<thead>
<tr><th>Parameter</th><th>Type</th><th>Description</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>request_id</td><td>String</td><td>The request id</td><td>This defaults to the originally sent id or is generated by the api</td></tr>
<tr><td>api</td><td>String</td><td>The api method which was called</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="output-parameters-webhook"></a><a href="#output-parameters-webhook" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Output Parameters (Webhook)</h3>
<table>
<thead>
<tr><th>Parameter</th><th>Type</th><th>Description</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>request_id</td><td>String</td><td>The request id</td><td>This defaults to the originally sent id or is generated by the api</td></tr>
<tr><td>segments</td><td>List</td><td>List of identified segments</td><td>The Speaker Identification Segment object is defined below</td></tr>
</tbody>
</table>
<h4><a class="anchor" aria-hidden="true" id="speaker-identification-segment"></a><a href="#speaker-identification-segment" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Speaker Identification Segment</h4>
<table>
<thead>
<tr><th>Parameter</th><th>Type</th><th>Description</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>speaker_id</td><td>String</td><td>speaker id of the identified speaker.</td></tr>
<tr><td>start</td><td>Float</td><td>Start of the audio segment.</td></tr>
<tr><td>end</td><td>Float</td><td>end of the audio segment.</td></tr>
</tbody>
</table>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/speaker-enrollment-api.html">← Speaker Enrollment Api</a><a class="docs-next button" href="/docs/realtime-speaker-identification-api.html">Realtime Speaker Identification Api →</a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/deepaffects-logo.png" alt="DeepAffects" width="66" height="58"/></a><div><h5>Docs</h5><a href="/docs/en/doc1.html">Getting Started (or other categories)</a><a href="/docs/en/doc2.html">Guides (or other categories)</a><a href="/docs/en/doc3.html">API Reference (or other categories)</a></div><div><h5>Community</h5><a href="/en/users.html">User Showcase</a><a href="http://stackoverflow.com/questions/tagged/deepaffects/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/deepaffects" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="https://github.com/developer-docs">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="developer-docs" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><section class="copyright">Copyright © 2018 DeepAffects</section></footer></div></body></html>